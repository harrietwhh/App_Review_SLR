title,author,year,venue,evidence for review rating,evidence for review length,evidence for domain knowledge,evidence for textual content,evidence for dynamic nature,evidence for review sentiment,other information,summarization
A preliminary analysis of mobile app user reviews,Vasa et al.,2012,OZCHI,RQ 2) Does the star rating affect the length of a review?,"RQs: 1) What is the size of a user review and is there an average length? 2) Does the star rating affect the length of a review?, and 3) Does the category of an app influence the length of areview?",RQ 3) Does the category of an app influence the length of a review?,,,,,"Star rating, review length, app category."
Analysis of user comments: An approach for software requirements evolution,Carreno and Winbladh,2013 ,ICSE,"As further information we have the number of “stars” per comment, as ratings, to include.",,,,,"However, we still need the sentiment, or a representative comment to understand what users think of each topic.",,"Rating, sentiment."
Why people hate your app: making sense of user feedback in a mobile app store,Fu et al.,2013 ,KDD,"Each user review consists of a timestamp showing when the review was created, a user rating, and the user's comment in the text form.",User reviews on mobile app stores differ from other online stores in two significant aspects: (a) these reviews are generally shorter in length since a large portion of them are submitted from mobile devices on which typing is not so easy;,,"0. Each user review consists of a timestamp showing when the review was created, a user rating, and the user's comment in the text form.
1. allow people to easily absorb information contained in large set of text reviews and numerical ratings by offering multiple forms of summarization.
2. In the micro level analysis, we target individual text comments.","User reviews on mobile app stores differ from other online stores in two significant aspects: (b) individual app may have multiple releases, therefore reviews are often specific to a particular version and vary over time.","1. Per review analysis (Micro level, Section 4): identifying sentiments and their strength in each review;.
1.1. In the micro level analysis, we target individual text comments and perform word-level analysis to understand the impact of each word on users' actual sentiments. This analysis helps us identify the vocabulary users used to praise or criticize apps.",,"Rating, text comment, shorter in length, submitted from mobile devices on which typing is not so easy, timestamp, reviews are often specific to a particular version and vary over time, sentiment."
Retrieving and analyzing mobile apps feature requests from online reviews,Iacob and Harrison,2013 ,MSR,"meta-data associated with each review is also collected for further analysis. Such meta-data includes the date the review was posted, the rating the user gave, the device associated to the review, the version of the app used by the user, and the title the user associated the review with.","reviews have a style of their own; they are usually short, unstructured and seldom obey grammar and punctuation rules.","(device) For each review, we automatically collected the date it was posted, the rating the user gave, the device associated with it, and the version of the app, as well as the title and the text of the actual review.","for developers, reviews are evaluations which may include ideas for improvement or feature requests.... reviews have a style of their own; they are usually short, unstructured and seldom obey grammar and punctuation rules. Moreover, users express opinions in unconventional ways, often using unconventional syntax or sarcasm to vent their feelings after purchasing an app. Even though humans can usually interpret such reviews, it is challenging to automate such interpretations [6].","meta-data associated with each review is also collected for further analysis. Such meta-data includes the date the review was posted, the rating the user gave, the device associated to the review, the version of the app used by the user, and the title the user associated the review with.",,"(massive) First, the number of reviews associated with one app often exceeds a human's capacity to read them all in order to identify recurring issues and trends.","Posting date, rating, device, app version, style (short, unstructured and seldom obey grammar and punctuation rules), using unconventional syntax or sarcasm, a large number of reviews."
User feedback in the appstore: An empirical study,Pagano and Maalej,2013 ,RE,"Feedback meta-data: What is a typical user feedback in terms of length, ratings, and helpfulness?","Feedback meta-data: What is a typical user feedback in terms of length, ratings, and helpfulness?",,"Feedback content describes topics (i.e. semantic entities) provided in the feedback information and their frequencies. In particular, we investigate the following questions:
1.1. Feedback type: Which types of user feedback exist?
1.2. Feedback patterns: Are there patterns in the co-occurrences of feedback types?",Feedback frequency: When and how often do users provide feedback?,,,"Length, ratings, helpfulness, feedback content (feedback type and pattern), feedback frequency."
AR-miner: mining informative reviews for developers from mobile app marketplace,Chen et al.,2014 ,ICSE,"Consider an individual app, in a time interval T , it receives a list of user reviews R* with an attribute set A... Without loss of generality, in this work, we choose A = {Text, Rating, Timestamp}, since these are the common attributes supported in all main-stream app marketplaces.",,,"These (app) reviews present user feedback on various aspects of apps (such as functionality, quality, performance, etc), and provide app developers a new and critical channel to extract user feed-back. However, comparing with traditional channels, there are two outstanding obstacles for app developers to obtain valuable information from this new channel. First of all, the proportion of ""informative"" user reviews is relatively low. In our study (see Section 5.1), we found that only 35.1% of app reviews contain information that can directly help developers improve their apps.","Consider an individual app, in a time interval T , it receives a list of user reviews R* with an attribute set A... Without loss of generality, in this work, we choose A = {Text, Rating, Timestamp}, since these are the common attributes supported in all main-stream app marketplaces.",,"(massive) Second, for some popular apps, the volume of user reviews is simply too large to do manual checking on all of them.","Text, rating, timestamp, the proportion of ""informative"" user reviews is relatively low, the volume of user reviews is simply too large."
How Do Users Like This Feature? A Fine Grained Sentiment Analysis of App Reviews,Guzman and Maalej,2014 ,RE,"However, there are several limitations which prevent analysts and development teams from using the information in the reviews... The usefulness of the star ratings in the reviews is limited for development teams, since a rating represents an average for the whole app and can combine both positive and negative evaluations of the single features.","For analyzing sentiments in user reviews, we use SentiStrength [28], a lexical sentiment extraction tool specialized in dealing with short, low quality text.... Pagano and Maalej [21] found that 80.4% of the comment reviews in the App Store contain less than 160 characters, making SentiStrength a good candidate for analyzing sentiments in user reviews.",,"Recent empirical studies [4], [6], [21] showed that app store reviews include information that is useful to analysts and app designers, such as user requirements, bug reports, feature requests, and documentation of user experiences with specific app features. This feedback can represent a ""voice of the users"" and be used to drive the development effort and improve forthcoming releases [15], [25].
However, there are several limitations which prevent analysts and development teams from using the information in the reviews... Second, the quality of the reviews varies widely, from helpful advice and innovative ideas to insulting comments.",,"However, there are several limitations which prevent analysts and development teams from using the information in the reviews... Third, a review typically contains a sentiment mix concerning the different app features, making it difficult to, e.g., filter positive and negative feedback or retrieve the feedback for specific features.",,"Star rating, sentiment, short (less than 160 characters), the quality of the reviews varying widely."
Ensemble Methods for App Review Classification: An Approach for Software Evolution,Guzman et al.,2015,ASE,"1. For each review, the title, comment and rating were displayed and the annotators labeled the corresponding categories of the review.

2. To train each classifier we apply the following steps on the title and comment of each single review: ... (3) add additional features into the vector space model for each review, i.e. review rating, number of words in the review, number of characters in the review, number of lower case characters, number of upper case characters, number of exclamation marks, number of ”@” symbols, number of spaces, average word length, ratio of positive sentiment words, ratio of negative sentiment words.","To train each classifier we apply the following steps on the title and comment of each single review: ... (3) add additional features into the vector space model for each review, i.e. review rating, number of words in the review, number of characters in the review, number of lower case characters, number of upper case characters, number of exclamation marks, number of ”@” symbols, number of spaces, average word length, ratio of positive sentiment words, ratio of negative sentiment words.",,"the processing of feedback from app stores presents three main challenges: (2) the relatively low proportion of informative user reviews. Previous research [5], [6], [4] found that about one third of the reviews contain information that can be useful for the evolution of the app, i.e. bug reports, feature requests and user scenarios and (3) the unstructured nature of app reviews. In app stores feedback is given in free form and no predetermined fields are used.",,"To train each classifier we apply the following steps on the title and comment of each single review: ... (3) add additional features into the vector space model for each review, i.e. review rating, number of words in the review, number of characters in the review, number of lower case characters, number of upper case characters, number of exclamation marks, number of ”@” symbols, number of spaces, average word length, ratio of positive sentiment words, ratio of negative sentiment words.",(massive) the processing of feedback from app stores presents three main challenges: (1) the high amount of user reviews for popular apps.,"Title, comment, rating, number of words in the review, number of characters in the review, ratio of positive sentiment words, ratio of negative sentiment words, relatively low proportion of informative user reviews, unstructured nature of app reviews, free form, high amount of user reviews for popular apps."
What Do Mobile App Users Complain About?,Khalid et al.,2015 ,IEEE Software,"Poor reviews affect sales more than good reviews because buyers are more likely to react to low ratings and complaints. So, to understand why users give low ratings to iOS apps, we focused on reviews with one- and two-star ratings. We explored two sources of information: the star ratings and their associated comments.",,,"Poor reviews affect sales more than good reviews because buyers are more likely to react to low ratings and complaints.So, to understand why users give low ratings to iOS apps, we focused on reviews with one- and two-star ratings. We explored two sources of information: the star ratings and their associated comments.",,,,"Rating, comment."
"Bug report, feature request, or simply praise? On automatically classifying app reviews",Maalej and Nabil,2015 ,RE,"1. Review Metadata: Rating and Length
1.1.Common metadata that can be collected with the reviews include the star rating, the length, and the submission time.","1. Review Metadata: Rating and Length
1.1.Common metadata that can be collected with the reviews include the star rating, the length, and the submission time.","Common metadata that can be collected with the reviews include the star rating, the length, and the submission time.","Recent research has pointed the potential importance of the reviews for the app developers and vendors as well. A significant amount of the reviews include requirements-related information such as bugs or issues [27], summary of the user experience with certain features [12], requests for enhancements [18], and even ideas for new features [8], [27]. Unfortunately, there are also a bunch of useless, low quality reviews, which include senseless information, insulting comments, spam, or just repetition of the star rating in words. With hundreds of reviews submitted per day for popular apps [16], [27], it becomes difficult for developers and analysts to filter and process useful information from the reviews.",,Reviews in the app stores usually reflect users' positive and negative emotions [12].,,"Star rating, length, submission time, a bunch of useless, low quality reviews, reflecting positive and negative emotions."
The App Sampling Problem for App Store Mining,Martin et al.,2015,MSR,"A unique review is defined by the rating, review body and author name.",,"A unique review is defined by the rating, review body and author name.",We use the (reviews identified as user) requests and try to learn about their content.,,,,"Rating, review body, author name."
How can i improve my app? Classifying user reviews for software maintenance and evolution,Panichella et al.,2015,ICSME,"App Stores, such as Google Play or the Apple Store, allow users to provide feedback on apps by posting review comments and giving star ratings.",,,"However, in the case of the most popular apps, the large amount of received feedback, its unstructured nature and varying quality can make the identification of useful user feedback a very challenging task.

1.2. Previous work [10], [18], [31] has shown that approximately one third of the information contained in user reviews is helpful for developers.

1.3. In addition, the quality of reviews varies greatly, from useful reviews providing ideas for improvement or describing specific issues to generic praises and complaints (e.g. “You have to be stupid to program this app”, “love it!”, “this app is useless”).",,,"(massive) However, in the case of the most popular apps, the large amount of received feedback, its unstructured nature and varying quality can make the identification of useful user feedback a very challenging task.","Review comment, star rating, a large amount of received feedback, unstructured nature, varying quality."
User reviews matter! Tracking crowdsourced reviews to support evolution of successful apps,Palomba et al.,2015 ,ICSME,"The quantitative part of the mechanism is implemented in a form of scores, usually expressed as a choice of one to five stars.","in most cases user reviews are notably shorter than issue descriptions and, as a consequence, their vocabulary is fairly limited.","Also, unlike issue reports and emails, reviews do not refer to implementation details. In other words, there is a vocabulary mismatch between user reviews and source code or issues reported in issue trackers.","1. First, as shown by Chen et al. [8], not all the reviews can be considered useful and/or informative.

2. The textual part of the rating mechanism is a free text description that does not have a predefined structure and is used to describe informally bugs and desired features.",,,,"Stars, notably shorter than issue descriptions, limited vocabulary, vocabulary mismatch between user reviews and source code or issues reported in issue trackers, free text, without predefined structure, describing informally bugs and desired features."
"""What Parts of Your Apps are Loved by Users?""",Gu and Kim,2015 ,ASE,Users' ratings can provide such summarization objectively.,,,,,"Such assumption may be problematic for software reviews which exhibit multiple purposes (e.g., aspect evaluation and feature request) and sentiments.","(massive) First, the volume of user reviews is too large to be checked manually. Developers receive hundreds or thousands of reviews every day [10], [31]. Given the large number of reviews, they need to read and manually classify the reviews into complaints or new feature requests [30]. Such processes are extremely time-consuming and tedious. On the other hand, user reviews fall into too many varieties that need to be distinguished [31]. They can be new feature requests, bug reports, praises, or complaints. Different types of reviews target different tasks and developers [30]. For example, a praising review may not be valuable for software testing but can be essential for product evaluation. A review reporting a bug is not important for requirements analysis but can be crucial for software testing. Given millions of reviews, developers must first categorize them manually [30].","Rating, sentiment, the volume of user reviews is too large."
Mining User Opinions in Mobile App Reviews: A Keyword-Based Approach,Phong et al.,2015 ,ASE,,,,"First, a popular app with millions of users often gets thousands of reviews each day and reading all of those reviews would be very time-consuming. In addition, user reviews of mobile apps are often noisy. They can have typos, acronyms, abbreviations, emoji icons, etc. Even worse, prior research reports that more than 60% of user reviews do not contain useful opinions [1].","Prior studies [1], [6] suggest that when a new version of an app is released with some severe defects or issues making many users unsatisfied, there are often sudden changes in occurrences of related topics in user reviews.",,"(massive) First, a popular app with millions of users often gets thousands of reviews each day and reading all of those reviews would be very time-consuming.","Thousands of reviews each day, noisy (typos, acronyms, abbreviations, emoji icons), 60% of user reviews do not contain useful opinions, review topics affected by app releases."
What would users change in my app? summarizing app reviews for recommending software changes,Di Sorbo et al.,2016 ,FSE,"we developed an XML data exchange schema for representing review data from multiple sources. For each user review, it stores: (i) the date on which the review has been posted, (ii) the (star) rating given by the reviewer, (iii) the handle of the user who posted the review, (iv) the version of the app, (v) the title of the review, and (vi) the review text itself.","Review length: longer sentences are usually more informative than shorter ones... In particular, we discarded all sentences with less than 3 tokens (e.g., ""Good app"", ""Great feature"", etc.), which rarely provide useful information for developers.",author’s nickname,"For each user review involved in our study, we collected the title, comment and posting date, the author’s nickname, the version of the app to which the review is referring, and the star rating.","For each user review involved in our study, we collected the title, comment and posting date, the author’s nickname, the version of the app to which the review is referring, and the star rating.","These reviews may not only contain simple sentiments (e.g., ""Great app!""), but they can provide valuable information regarding several topics that are highly relevant to the development and maintenance of the app [19, 29].",,"Title, review text, posting date, user handle, app version, star rating, review length, sentiment."
On the automatic classification of app reviews,Maalej et al.,2016 ,Requirements Engineering,"A user review consists of a main text part and additional metadata. ... Common metadata that can be collected with the reviews includes the star rating, the length, and the submission time.","A user review consists of a main text part and additional metadata. ... Common metadata that can be collected with the reviews includes the star rating, the length, and the submission time.",,"Using free text and star rating, the users are able to express their satisfaction, dissatisfaction or ask for missing features. Moreover, recent research has pointed the potential importance of the reviews for the app developers and vendors as well. A significant amount of the reviews include requirements-related information such as bugs or issues [29], summary of the user experience with certain features [12], requests for enhancements [19], and even ideas for new features [8, 29].... Unfortunately, there are also a bunch of useless, low-quality reviews, which include senseless information, insulting comments, spam, or just repetition of the star rating in words.","A user review consists of a main text part and additional metadata. ... Common metadata that can be collected with the reviews includes the star rating, the length, and the submission time.",Reviews in the app stores usually reflect users’ positive and negative emotions [12]. More fine-grained sentiments than the star rating can be extracted from the reviews and used as a feature for training the classifier.,"(massive) With hundreds of reviews submitted per day for popular apps [17, 29], it becomes difficult for developers and analysts to filter and process useful information from the reviews.","Star rating, length, submission time, free text, a bunch of useless, low-quality reviews, sentiment, hundreds of reviews submitted per day for popular apps."
Toward Data-Driven Requirements Engineering,Maalej et al.,2016 ,IEEE Software,,"But they give short, uninformative reviews for negative ratings, such as “fire the idiot who developed this app,” or “worst experience since dating my ex.”",,,,"Users tend to discuss what led to positive experiences (and thus positive ratings). But they give short, uninformative reviews for negative ratings, such as “fire the idiot who developed this app,” or “worst experience since dating my ex.”",,"Short, uninformative reviews for negative ratings."
Analyzing and automatically labelling the types of user issues that are raised in mobile app reviews,McIlroy et al.,2016 ,EMSE,"Reviews in both stores contain a title, a date, a numerical rating between 1 and 5 (where 1 represents a poor app) and a comment section where the user is free to write whatever they wish.",,,"1. Such mobile app user reviews contain valuable information e.g. feature requests, functional complaints, and privacy issues. ... the unstructured and informal nature of reviews complicates the automated labelling of such reviews.

2. Moreover, such labelling is a difficult task due to the unstructured nature of reviews with many of them containing slang, lacking punctuation, and containing improper grammar.","1. Reviews in both stores contain a title, a date, a numerical rating between 1 and 5 (where 1 represents a poor app) and a comment section where the user is free to write whatever they wish.

2. ‘Update issue’ is in multi-labelled data 75 % of the time.",,"(massive) Due to the large number of user reviews and their free form, it is infeasible for stakeholders to fully benefit from the valuable information in user reviews through manual inspection.","Title, date, rating, the unstructured and informal nature of reviews, large number of user reviews, free form."
Release planning of mobile apps based on user reviews,Villarroel et al.,2016 ,ICSE,"1. User reviews and ratings are therefore very important assets in the development and evolution of mobile apps.
2. we use the rating of the user reviews and the terms/sentences they contain as predictor variables.",,,,"1. The typical app delivery mechanism is a store in which on the one hand new releases of the app are available for download, and, on the other hand, users rate the app and post reviews.

2. In addition, each app in the dataset is associated to a metadata file containing its basic information, including the ""updated"" optional field that app's developers can use to describe the changes they made to the different app's releases (i.e., a sort of release note shown in the Google Play store). We exploited such a dataset to build, for a given app, an oracle reporting which of the reviews left by its users for the release ri have been implemented by the developers in the release ri+1 (i.e., high priority reviews) and which, instead, have been ignored/postponed (i.e., low priority reviews).",,"(massive) However, manually read each user review and verify if it contains useful information (e.g., bug reporting or request for a new feature) is not doable for popular apps receiving hundreds of reviews per day.","Rating, release, hundreds of reviews per day."
